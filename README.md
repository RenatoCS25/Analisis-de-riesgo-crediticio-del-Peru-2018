# ğŸ§  AnÃ¡lisis de Riesgo Crediticio en el PerÃº

Este proyecto tiene como finalidad aplicar tÃ©cnicas de ciencia de datos y machine learning para abordar un problema real del sector financiero: **la evaluaciÃ³n del riesgo crediticio de potenciales clientes**.

A travÃ©s del anÃ¡lisis de datos histÃ³ricos de personas evaluadas por entidades financieras peruanas, se busca construir un modelo capaz de predecir con precisiÃ³n el nivel de riesgo crediticio que representa un solicitante, clasificÃ¡ndolo en distintas categorÃ­as (por ejemplo: bajo, medio, alto, etc.).

El modelo puede ser utilizado por instituciones financieras para optimizar decisiones relacionadas con la aprobaciÃ³n de prÃ©stamos, asignaciÃ³n de garantÃ­as o necesidad de avales. Una evaluaciÃ³n automatizada y precisa del riesgo reduce la morosidad y mejora la inclusiÃ³n financiera.

---

## ğŸ¯ Objetivo

Desarrollar un sistema predictivo de clasificaciÃ³n multiclase que, a partir de atributos personales y econÃ³micos de los solicitantes, determine su **segmentaciÃ³n de riesgo crediticio**. El modelo busca:

- Anticipar el nivel de riesgo (bajo, medio, alto, etc.) asociado a un cliente.
- Automatizar la evaluaciÃ³n de perfiles crediticios.
- Proporcionar una herramienta de apoyo a la toma de decisiones crediticias.
- Evaluar y comparar distintos algoritmos de clasificaciÃ³n aplicables al contexto financiero peruano.

El resultado final es un modelo entrenado, evaluado y documentado, listo para ser integrado como parte de un sistema de anÃ¡lisis de riesgo en entornos reales.


### ğŸ”¹ 2. ExploraciÃ³n inicial

Se analizÃ³:
- Estructura del dataset
- Tipos de datos
- DistribuciÃ³n de clases
- Variables categÃ³ricas y numÃ©ricas

---

### ğŸ”¹ 3. Limpieza de datos

- Tratamiento de valores faltantes
- ConversiÃ³n de tipos
- EliminaciÃ³n de columnas irrelevantes o redundantes

---

### ğŸ”¹ 4. AnÃ¡lisis exploratorio de datos (EDA)

- VisualizaciÃ³n de distribuciones y correlaciones
- AnÃ¡lisis por categorÃ­a de riesgo
- GrÃ¡ficos de barras y boxplots

---

### ğŸ”¹ 5. IngenierÃ­a de caracterÃ­sticas

- CodificaciÃ³n de variables categÃ³ricas con One-Hot Encoding
- CodificaciÃ³n de la variable objetivo con `LabelEncoder`
- EliminaciÃ³n de columnas irrelevantes para el modelo

---

### ğŸ”¹ 6. PreparaciÃ³n para el modelado

- SeparaciÃ³n entre variables predictoras (`X`) y variable objetivo (`y`)
- Escalado de variables numÃ©ricas con `StandardScaler` (solo para modelos lineales)

---

### ğŸ”¹ 7. DivisiÃ³n del conjunto de datos

- DivisiÃ³n del dataset en entrenamiento (70%) y prueba (30%)
- EstratificaciÃ³n para conservar proporciones de clases

---

### ğŸ”¹ 8. Entrenamiento de modelos

Se entrenaron y compararon dos modelos de clasificaciÃ³n multiclase:

- **RegresiÃ³n LogÃ­stica (`LogisticRegression`)**: modelo base con escalado de datos.
- **Random Forest (`RandomForestClassifier`)**: modelo robusto que no requiere escalado.

---

### ğŸ”¹ 9. EvaluaciÃ³n de modelos

- Reporte de clasificaciÃ³n (`classification_report`): precision, recall, f1-score
- Matriz de confusiÃ³n (`confusion_matrix`)
- VisualizaciÃ³n con heatmap (`Seaborn`)

---

### ğŸ”¹ 10. Conclusiones

- El modelo de **Random Forest superÃ³ a la regresiÃ³n logÃ­stica** en todas las mÃ©tricas.
- Mayor precisiÃ³n en clases minoritarias.
- Random Forest fue el modelo seleccionado para el portafolio.

---

## ğŸ› ï¸ Herramientas utilizadas

- Python
- Pandas, NumPy
- Scikit-learn
- Seaborn, Matplotlib

---

## ğŸ“‚ Estructura del proyecto

