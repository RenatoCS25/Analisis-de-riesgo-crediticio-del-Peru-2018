# ğŸ§  AnÃ¡lisis de Riesgo Crediticio en el PerÃº

Este proyecto aplica tÃ©cnicas de anÃ¡lisis de datos y aprendizaje automÃ¡tico para predecir la segmentaciÃ³n de riesgo crediticio de clientes, usando datos de entidades financieras peruanas. El modelo permite clasificar a los clientes en distintos niveles de riesgo para facilitar decisiones de crÃ©dito.

---

## ğŸ¯ Objetivo

Predecir la **segmentaciÃ³n de riesgo crediticio** (bajo, medio, alto, etc.) de un cliente con base en variables personales, econÃ³micas y financieras.

---

## ğŸ“Š Fases del proyecto

### ğŸ”¹ 1. Carga de datos

Se utilizÃ³ un archivo CSV con informaciÃ³n sobre clientes: sexo, edad, ingresos, tipo de vivienda, garantÃ­as, avales, actividad econÃ³mica y la clase de riesgo asignada.

---

### ğŸ”¹ 2. ExploraciÃ³n inicial

Se analizÃ³:
- Estructura del dataset
- Tipos de datos
- DistribuciÃ³n de clases
- Variables categÃ³ricas y numÃ©ricas

---

### ğŸ”¹ 3. Limpieza de datos

- Tratamiento de valores faltantes
- ConversiÃ³n de tipos
- EliminaciÃ³n de columnas irrelevantes o redundantes

---

### ğŸ”¹ 4. AnÃ¡lisis exploratorio de datos (EDA)

- VisualizaciÃ³n de distribuciones y correlaciones
- AnÃ¡lisis por categorÃ­a de riesgo
- GrÃ¡ficos de barras y boxplots

---

### ğŸ”¹ 5. IngenierÃ­a de caracterÃ­sticas

- CodificaciÃ³n de variables categÃ³ricas con One-Hot Encoding
- CodificaciÃ³n de la variable objetivo con `LabelEncoder`
- EliminaciÃ³n de columnas irrelevantes para el modelo

---

### ğŸ”¹ 6. PreparaciÃ³n para el modelado

- SeparaciÃ³n entre variables predictoras (`X`) y variable objetivo (`y`)
- Escalado de variables numÃ©ricas con `StandardScaler` (solo para modelos lineales)

---

### ğŸ”¹ 7. DivisiÃ³n del conjunto de datos

- DivisiÃ³n del dataset en entrenamiento (70%) y prueba (30%)
- EstratificaciÃ³n para conservar proporciones de clases

---

### ğŸ”¹ 8. Entrenamiento de modelos

Se entrenaron y compararon dos modelos de clasificaciÃ³n multiclase:

- **RegresiÃ³n LogÃ­stica (`LogisticRegression`)**: modelo base con escalado de datos.
- **Random Forest (`RandomForestClassifier`)**: modelo robusto que no requiere escalado.

---

### ğŸ”¹ 9. EvaluaciÃ³n de modelos

- Reporte de clasificaciÃ³n (`classification_report`): precision, recall, f1-score
- Matriz de confusiÃ³n (`confusion_matrix`)
- VisualizaciÃ³n con heatmap (`Seaborn`)

---

### ğŸ”¹ 10. Conclusiones

- El modelo de **Random Forest superÃ³ a la regresiÃ³n logÃ­stica** en todas las mÃ©tricas.
- Mayor precisiÃ³n en clases minoritarias.
- Random Forest fue el modelo seleccionado para el portafolio.

---

## ğŸ› ï¸ Herramientas utilizadas

- Python
- Pandas, NumPy
- Scikit-learn
- Seaborn, Matplotlib

---

## ğŸ“‚ Estructura del proyecto

